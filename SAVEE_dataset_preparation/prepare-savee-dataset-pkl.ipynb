{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from data import FeatureType\n",
    "from legacy.convert_iemocap_dataset_to_pkl import load_wav, split_audio, remove_silent, _get_mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Kingston/datasets/audio/SAVEE/AudioData'\n",
    "\n",
    "SPEAKERS = ['DC', 'JE', 'JK', 'KL']\n",
    "EMOTIONS = ['h', 'sa', 'a', 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_emotion(filepath:str):\n",
    "    filename = filepath.split('/')[-1]\n",
    "    emo = filename[0:-6]\n",
    "    if emo in EMOTIONS:\n",
    "        return EMOTIONS.index(emo)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_files = []\n",
    "for S in SPEAKERS:\n",
    "    speaker_dir = data_dir + '/' + S\n",
    "    file_list = glob.glob(speaker_dir + \"/*.wav\")\n",
    "    for f in file_list:\n",
    "        emotion = get_emotion(f)\n",
    "        if emotion is not None:\n",
    "            filtered_files.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Mean Audio File Length : 3.841959259259259\nSR: 44100\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "file_lengths = []\n",
    "sr = None\n",
    "for f in filtered_files:\n",
    "\n",
    "    audio, sr = librosa.load(f, sr=sr)\n",
    "    file_lengths.append(len(audio) / sr)\n",
    "\n",
    "file_lengths = np.array(file_lengths)\n",
    "print(\"Mean Audio File Length : {}\".format(np.mean(file_lengths)))\n",
    "print(\"SR: {}\".format(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_mfcc(filename, duration):\n",
    "    a, sr = load_wav(filename)\n",
    "    a = remove_silent(a)\n",
    "    signal_frame = split_audio(a, sr, duration)[0]\n",
    "    mfcc = _get_mfcc(signal_frame,sr)\n",
    "    return mfcc\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "end\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for f in filtered_files:\n",
    "    datum = {\n",
    "        FeatureType.MFCC.name: get_mfcc(f, 3), \n",
    "        'signal': load_wav(f), \n",
    "        'y_emo': to_categorical(get_emotion(f), num_classes=len(EMOTIONS),dtype='int'),\n",
    "        'filename': f.split('/')[-2] + '/' + f.split('/')[-1]\n",
    "    }\n",
    "    \n",
    "    data_list.append(datum)\n",
    "\n",
    "data_list = np.array(data_list)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "saved:  ../pkl/savee_sr_44k_3sec_4-classes.pkl\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "pkl_filename = \"../pkl/savee_sr_44k_3sec_{}-classes.pkl\".format(len(EMOTIONS))\n",
    "with open(pkl_filename, 'wb') as f:\n",
    "    pickle.dump(data_list, f)\n",
    "print(\"saved: \", pkl_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-classifier",
   "language": "python",
   "name": "rl-classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}